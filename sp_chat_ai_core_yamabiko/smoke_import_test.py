#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Smoke import test (Updated for Yamabiko)
- Verifies all imports actually used across modules (attributes included)
- Minimal instantiation checks for some libs (no network)
- Validates product_terms.json
- Prints package versions

Run:
  uv run python -m sp_chat_ai_core_yamabiko.smoke_import_test
  # ã¾ãŸã¯ä»®æƒ³ç’°å¢ƒã«å…¥ã£ã¦:
  python -m sp_chat_ai_core_yamabiko.smoke_import_test
"""

from __future__ import annotations
import importlib
import json
import sys
from pathlib import Path

# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åã‚’ç¾åœ¨ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã«åˆã‚ã›ã¦å®šç¾©
PKG_NAME = "sp_chat_ai_core_yamabiko"

print(f"ğŸ” Import smoke test for [{PKG_NAME}] started...\n")

failures: list[tuple[str, BaseException]] = []

def record(ok: bool, name: str, err: BaseException | None):
    if not ok:
        failures.append((name, err))

def check_module(mod: str) -> None:
    try:
        importlib.import_module(mod)
        print(f"âœ… {mod} OK")
    except Exception as e:
        print(f"âŒ {mod} failed: {e}")
        record(False, mod, e)

def check_attrs(mod: str, attrs: list[str]) -> None:
    try:
        m = importlib.import_module(mod)
    except Exception as e:
        print(f"âŒ {mod} import failed (skip attrs): {e}")
        record(False, mod, e)
        return
    for a in attrs:
        try:
            getattr(m, a)
            print(f"   â””â”€ âœ… {mod}.{a} OK")
        except Exception as e:
            print(f"   â””â”€ âŒ {mod}.{a} failed: {e}")
            record(False, f"{mod}.{a}", e)

def get_version(mod_name: str) -> str | None:
    try:
        from importlib.metadata import version, PackageNotFoundError
        try:
            return version(mod_name)
        except PackageNotFoundError:
            pass
    except Exception:
        pass
    try:
        m = importlib.import_module(mod_name)
        return getattr(m, "__version__", None) or getattr(m, "VERSION", None)
    except Exception:
        return None

# ========== 1) Modules: presence ==========
module_targets = [
    # External Libs
    "openai",
    "google.genai",
    "google.genai.types",
    "langgraph.graph",
    "langchain_core.messages",
    "google.cloud.secretmanager",
    "google.cloud.bigquery",
    "google.cloud.firestore",
    "google.cloud.spanner_v1",
    "janome.tokenizer",
    "rank_bm25",
    "pandas",
    "numpy",
    "pydantic",

    # Internal Modules (Project Specific)
    f"{PKG_NAME}.chat_engine_adk_bq",
    f"{PKG_NAME}.retriever_adk_bq",
    f"{PKG_NAME}.chat_memory",
    f"{PKG_NAME}.firestore_memory_yamabiko",  # ä»Šå›ä¿®æ­£ã—ãŸç®‡æ‰€
    f"{PKG_NAME}.google_secret_manager",
    f"{PKG_NAME}.support_operation_agent",     # Agentæœ¬ä½“
]

for mod in module_targets:
    check_module(mod)

# ========== 2) Attribute-level checks ==========
attr_checks = {
    # typing / standard
    "typing": ["TypedDict", "Annotated", "List", "Sequence", "Dict"],

    # langgraph / langchain
    "langgraph.graph": ["StateGraph", "END"],
    "langchain_core.messages": ["BaseMessage", "HumanMessage", "AIMessage"],

    # Internal Attributes
    f"{PKG_NAME}.chat_engine_adk_bq": ["AdkChatbot"],
    f"{PKG_NAME}.retriever_adk_bq": ["RefactoredRetriever"], # ã‚¯ãƒ©ã‚¹åãŒç•°ãªã‚‹å ´åˆã¯ä¿®æ­£ã—ã¦ãã ã•ã„
    f"{PKG_NAME}.chat_memory": ["BaseMemory"],
    f"{PKG_NAME}.firestore_memory_yamabiko": ["FirestoreMemory"], # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‹ã‚‰æ¨æ¸¬ã•ã‚Œã‚‹ã‚¯ãƒ©ã‚¹å
    f"{PKG_NAME}.google_secret_manager": [],
    # Agentã¯TopLevelã§ã®å®Ÿè¡Œã‚³ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹å ´åˆãŒã‚ã‚‹ãŸã‚ã€å±æ€§ãƒã‚§ãƒƒã‚¯ã¯å¿…é ˆã§ã¯ãªã„ãŒã€importè‡ªä½“ã¯ä¸Šã§ç¢ºèªæ¸ˆã¿
}

for mod, attrs in attr_checks.items():
    check_attrs(mod, attrs)

# ========== 3) Minimal instantiation checks (No Network) ==========
try:
    from janome.tokenizer import Tokenizer
    _t = Tokenizer()
    toks = [t.surface for t in _t.tokenize("ã‚¹ãƒ¢ãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­")]
    assert isinstance(toks, list)
    print("âœ… janome.Tokenizer minimal tokenize OK")
except Exception as e:
    print(f"âŒ janome.Tokenizer failed: {e}")
    record(False, "janome.Tokenizer()", e)

try:
    from rank_bm25 import BM25Okapi
    bm25 = BM25Okapi([["test", "start"], ["smoke", "check"]])
    _ = bm25.get_scores(["check"])
    print("âœ… rank_bm25.BM25Okapi minimal init OK")
except Exception as e:
    print(f"âŒ rank_bm25.BM25Okapi failed: {e}")
    record(False, "rank_bm25.BM25Okapi()", e)

# ========== 4) Local resource validation ==========
# ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«è‡ªèº«(__file__)ã¨åŒã˜éšå±¤ã«ã‚ã‚‹ product_terms.json ã‚’æ¢ã—ã«è¡Œãã¾ã™
repo_root = Path(__file__).resolve().parent
json_path = repo_root / "product_terms.json"

if json_path.exists():
    try:
        text = json_path.read_text(encoding="utf-8")
        data = json.loads(text)
        print(f"âœ… product_terms.json loaded OK (len={len(data) if hasattr(data,'__len__') else 'n/a'})")
    except Exception as e:
        print(f"âŒ product_terms.json validation failed: {e}")
        record(False, "product_terms.json", e)
else:
    print(f"âš ï¸ product_terms.json not found at {json_path}")
    # å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ãªã‚‰ record(False, ...) ã«å¤‰æ›´ã—ã¦ãã ã•ã„

# ========== 5) Versions ==========
print("\nğŸ“¦ Versions:")
pkgs_to_check = [
    "google-genai", "langgraph", "langchain-core",
    "pandas", "numpy", "rank-bm25", "janome", "pydantic",
    # å†…éƒ¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«è‡ªä½“ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒã‚ã‚Œã°
]
for pkg in pkgs_to_check:
    ver = get_version(pkg)
    if ver:
        print(f"   - {pkg: <15} : {ver}")

# ========== 6) Summary ==========
print("\n" + "=" * 60)
if failures:
    print(f"âŒ NG: {len(failures)} checks failed")
    for name, err in failures:
        print(f"  - {name}: {err}")
    sys.exit(1)
else:
    print("âœ… All required imports & checks succeeded. System is ready! ğŸ‰")